<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on cocowen&#39;s blog</title>
    <link>https://cocowenlw.github.io/posts/</link>
    <description>Recent content in Posts on cocowen&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Wed, 13 Oct 2021 19:42:48 +0800</lastBuildDate>
    
	<atom:link href="https://cocowenlw.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Center Selection Algorithm</title>
      <link>https://cocowenlw.github.io/first_post/</link>
      <pubDate>Wed, 13 Oct 2021 19:42:48 +0800</pubDate>
      
      <guid>https://cocowenlw.github.io/first_post/</guid>
      <description>Center Selection Algorithm &amp;emsp;&amp;emsp;In the k-means algorithm, we can start with (i) using an initial partition {S1, S2, ..., Sk} or with (ii) using initial centers {c1, c2, ..., ck}. Design a good initialization method for k-means algorithm for (i) and also for (ii)   题目相当于问k-means方法的初始化。常规的来说有三种方法，第一种随机选择初始点，第二种k-means++，第三种基于层次的初始化。对于聚类初始化算法来说，其效率很大程度上是跟其初始数据有关的，所以很难说某种算法非常的优秀，但总体上来说，k-means++应该是使用最广泛的一种。
首先来讲一下kmeans++算法
1、随机选取第一个中心
2、计算每个样本和已有聚类中心的最短距离。下一个中心被选中的概率与这个最短距离的平方成正比。D(xi)=min||xi−cr||2 其中D(xi)越大，选中概率越大。
3、然后一直重复第二个步骤，直到选出K个中心点来。 </description>
    </item>
    
  </channel>
</rss>